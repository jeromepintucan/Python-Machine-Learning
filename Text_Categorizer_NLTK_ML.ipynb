{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Jerome\n",
      "[nltk_data]     Pintucan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jerome\n",
      "[nltk_data]     Pintucan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Jerome\n",
      "[nltk_data]     Pintucan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Jerome\n",
      "[nltk_data]     Pintucan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'clf__alpha': 0.1, 'tfidf__max_df': 0.7, 'tfidf__ngram_range': (1, 2)}\n",
      "Accuracy: 0.825\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Food Quality and Taste       0.85      0.94      0.89        54\n",
      "        Order Accuracy       0.73      0.67      0.70        12\n",
      "               Portion       0.83      0.83      0.83         6\n",
      "               Pricing       0.67      0.25      0.36         8\n",
      "\n",
      "              accuracy                           0.82        80\n",
      "             macro avg       0.77      0.67      0.70        80\n",
      "          weighted avg       0.81      0.82      0.81        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'CommentKeywords.xlsx'\n",
    "\n",
    "data = pd.read_excel(path)\n",
    "\n",
    "def column_cleaner(selected_column):\n",
    "    data[selected_column] = data[selected_column].str.lower()\n",
    "    data[selected_column] = data[selected_column].str.strip()\n",
    "    data[selected_column].drop_duplicates(keep='first', inplace=True)\n",
    "    return data\n",
    "\n",
    "data = column_cleaner('Key Words')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_stop_words = set(stopwords.words('english'))\n",
    "filipino_stop_words = set(stopwords.words('filipino'))\n",
    "chinese_stop_words = set(stopwords.words('chinese'))\n",
    "stop_words = english_stop_words | filipino_stop_words | chinese_stop_words\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['Key Words'] = data['Key Words'].apply(preprocess_text)\n",
    "\n",
    "# Adding a feature: Length of comments\n",
    "data['Comment Length'] = data['Key Words'].apply(lambda x: len(x.split()))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data[['Key Words', 'Comment Length']], data['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Multinomial Naive Bayes\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'clf__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(text_clf, X_train['Key Words'], y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, param_grid, cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_train['Key Words'], y_train)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_val['Key Words'])\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)\n",
    "\n",
    "# Sentiment Analysis\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(comment):\n",
    "    sentiment_scores = sid.polarity_scores(comment)\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Predicted Category</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Best Stewed Pork :)</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Jap Comfort Food</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super Yummy!!!! My</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great Food As Always!!</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tasty</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perfect!❤️❤️❤️</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Their Lu Rou Fan Is The Bomb!!! Their</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I Super Like The Gyoza And The Chicken</td>\n",
       "      <td>Food Quality and Taste</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I Requested Utensils But The Store Did Not</td>\n",
       "      <td>Order Accuracy</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Comments      Predicted Category  \\\n",
       "0                                        Best  Food Quality and Taste   \n",
       "1                     The Best Stewed Pork :)  Food Quality and Taste   \n",
       "2                        New Jap Comfort Food  Food Quality and Taste   \n",
       "3                          Super Yummy!!!! My  Food Quality and Taste   \n",
       "4                      Great Food As Always!!  Food Quality and Taste   \n",
       "5                                       Tasty  Food Quality and Taste   \n",
       "6                              Perfect!❤️❤️❤️  Food Quality and Taste   \n",
       "7       Their Lu Rou Fan Is The Bomb!!! Their  Food Quality and Taste   \n",
       "8      I Super Like The Gyoza And The Chicken  Food Quality and Taste   \n",
       "9  I Requested Utensils But The Store Did Not          Order Accuracy   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  positive  \n",
       "4  positive  \n",
       "5   neutral  \n",
       "6   neutral  \n",
       "7  negative  \n",
       "8  positive  \n",
       "9   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'] = data['Key Words'].apply(analyze_sentiment)\n",
    "\n",
    "target_path = 'JKT Reviews.xlsx'\n",
    "target_comment = pd.read_excel(target_path)\n",
    "target_comments = target_comment['Review'].tolist()\n",
    "\n",
    "sentiments = [analyze_sentiment(comment) for comment in target_comments]\n",
    "X_target = pd.DataFrame({'Comments': target_comments, 'Sentiment': sentiments})\n",
    "predicted_categories = grid_search.predict(X_target['Comments'])\n",
    "\n",
    "df = pd.DataFrame({'Comments': target_comments, 'Predicted Category': predicted_categories, 'Sentiment': sentiments})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
